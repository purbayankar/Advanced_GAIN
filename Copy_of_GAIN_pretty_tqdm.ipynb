{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pt]",
      "language": "python",
      "name": "conda-env-pt-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Copy of GAIN-pretty-tqdm.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24f0629818c8489d82a00e45669556d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa0fcfc268d24bf0895367aa67f65efa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b166ec2feb04128b332db66a1990876",
              "IPY_MODEL_968f367e54ab4a14a9ace2f9bccf2592"
            ]
          }
        },
        "fa0fcfc268d24bf0895367aa67f65efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b166ec2feb04128b332db66a1990876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffd36c1d19df4571a9704be243e785c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e1e38403ba54a4a8b9f094c2650ef79"
          }
        },
        "968f367e54ab4a14a9ace2f9bccf2592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f3ed440f7a046a7a098737e34cda9e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/5000 [00:26&lt;00:00, 189.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba1bd7f75b194d84bfba214350edfc8d"
          }
        },
        "ffd36c1d19df4571a9704be243e785c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e1e38403ba54a4a8b9f094c2650ef79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f3ed440f7a046a7a098737e34cda9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba1bd7f75b194d84bfba214350edfc8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purbayankar/Advanced_GAIN/blob/main/Copy_of_GAIN_pretty_tqdm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thZs1YwD9Irt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3155f1-c7d6-48d5-931d-12d111d8c09f"
      },
      "source": [
        "!git clone https://github.com/dhanajitb/GAIN-Pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GAIN-Pytorch'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 19 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-28kjHT9S1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15015e9-ba7d-44e8-df54-e1af7e34179e"
      },
      "source": [
        "cd GAIN-Pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GAIN-Pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKxa58Fq9Fsq"
      },
      "source": [
        "Creator: Dhanajit Brahma\n",
        "\n",
        "Adapted from the original implementation in tensorflow from here: https://github.com/jsyoon0823/GAIN\n",
        "\n",
        "Generative Adversarial Imputation Networks (GAIN) Implementation on Letter and Spam Dataset\n",
        "\n",
        "Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data Imputation using Generative Adversarial Nets,\" ICML, 2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1zzMwBV9Fs1"
      },
      "source": [
        "#%% Packages\n",
        "import torch\n",
        "import numpy as np\n",
        "# from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx4_vlso9Fs4"
      },
      "source": [
        "dataset_file = 'Spam.csv'  # 'Letter.csv' for Letter dataset an 'Spam.csv' for Spam dataset\n",
        "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
        "\n",
        "if use_gpu:\n",
        "    torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eutxur_X9Fs5"
      },
      "source": [
        "#%% System Parameters\n",
        "# 1. Mini batch size\n",
        "mb_size = 128\n",
        "# 2. Missing rate\n",
        "p_miss = 0.2\n",
        "# 3. Hint rate\n",
        "p_hint = 0.9\n",
        "# 4. Loss Hyperparameters\n",
        "alpha = 10\n",
        "# 5. Train Rate\n",
        "train_rate = 0.8\n",
        "\n",
        "#%% Data\n",
        "\n",
        "# Data generation\n",
        "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
        "\n",
        "# Parameters\n",
        "No = len(Data)\n",
        "Dim = len(Data[0,:])\n",
        "\n",
        "# Hidden state dimensions\n",
        "H_Dim1 = Dim\n",
        "H_Dim2 = Dim\n",
        "\n",
        "# Normalization (0 to 1)\n",
        "Min_Val = np.zeros(Dim)\n",
        "Max_Val = np.zeros(Dim)\n",
        "\n",
        "for i in range(Dim):\n",
        "    Min_Val[i] = np.min(Data[:,i])\n",
        "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
        "    Max_Val[i] = np.max(Data[:,i])\n",
        "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
        "\n",
        "#%% Missing introducing\n",
        "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
        "   \n",
        "Missing = np.zeros((No,Dim))\n",
        "\n",
        "for i in range(Dim):\n",
        "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
        "    B = A > p_miss_vec[i]\n",
        "    Missing[:,i] = 1.*B\n",
        "\n",
        "    \n",
        "#%% Train Test Division    \n",
        "   \n",
        "idx = np.random.permutation(No)\n",
        "\n",
        "Train_No = int(No * train_rate)\n",
        "Test_No = No - Train_No\n",
        "    \n",
        "# Train / Test Features\n",
        "trainX = Data[idx[:Train_No],:]\n",
        "testX = Data[idx[Train_No:],:]\n",
        "\n",
        "# Train / Test Missing Indicators\n",
        "trainM = Missing[idx[:Train_No],:]\n",
        "testM = Missing[idx[Train_No:],:]\n",
        "\n",
        "#%% Necessary Functions\n",
        "\n",
        "# 1. Xavier Initialization Definition\n",
        "# def xavier_init(size):\n",
        "#     in_dim = size[0]\n",
        "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
        "    return np.random.normal(size = size, scale = xavier_stddev)\n",
        "    \n",
        "# Hint Vector Generation\n",
        "def sample_M(m, n, p):\n",
        "    A = np.random.uniform(0., 1., size = [m, n])\n",
        "    B = A > p\n",
        "    C = 1.*B\n",
        "    return C\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NZvdmQT9Fs6"
      },
      "source": [
        "### GAIN Architecture   \n",
        "GAIN Consists of 3 Components\n",
        "- Generator\n",
        "- Discriminator\n",
        "- Hint Mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyP_IY5a9Fs7"
      },
      "source": [
        "#%% 1. Discriminator\n",
        "if use_gpu is True:\n",
        "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
        "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
        "\n",
        "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
        "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
        "\n",
        "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
        "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
        "else:\n",
        "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
        "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
        "\n",
        "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
        "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
        "\n",
        "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
        "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
        "\n",
        "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
        "\n",
        "#%% 2. Generator\n",
        "if use_gpu is True:\n",
        "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
        "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
        "\n",
        "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
        "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
        "\n",
        "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
        "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
        "else:\n",
        "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
        "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
        "\n",
        "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
        "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
        "\n",
        "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
        "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
        "\n",
        "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPgkyzEM9Fs8"
      },
      "source": [
        "## GAIN Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx8zjGZM9Fs-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#%% 1. Generator\n",
        "# def generator(new_x,m):\n",
        "#     inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
        "#     G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
        "#     G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
        "#     G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
        "    \n",
        "#     return G_prob\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(generator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(114,57),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(57,57),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, new_x, m):\n",
        "        inputs = torch.cat(dim = 1, tensors = [new_x,m])\n",
        "        output = torch.sigmoid(self.fc(inputs))\n",
        "        return output\n",
        "\n",
        "generator = generator()\n",
        "\n",
        "\n",
        "#%% 2. Discriminator\n",
        "# def discriminator(new_x, h):\n",
        "#     inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
        "#     D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
        "#     D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
        "#     D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
        "#     D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
        "    \n",
        "#     return D_prob\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(114,57),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(57,57),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, new_x, m):\n",
        "        inputs = torch.cat(dim = 1, tensors = [new_x,m])\n",
        "        output = torch.sigmoid(self.fc(inputs))\n",
        "        return output\n",
        "\n",
        "discriminator = discriminator()\n",
        "\n",
        "#%% 3. Other functions\n",
        "# Random sample generator for Z\n",
        "def sample_Z(m, n):\n",
        "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
        "\n",
        "# Mini-batch generation\n",
        "def sample_idx(m, n):\n",
        "    A = np.random.permutation(m)\n",
        "    idx = A[:n]\n",
        "    return idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L10mMHLz9Fs_"
      },
      "source": [
        "## GAIN Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePi76XVY9FtA"
      },
      "source": [
        "def discriminator_loss(M, New_X, H):\n",
        "    # Generator\n",
        "    G_sample = generator(New_X,M)\n",
        "    # Combine with original data\n",
        "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
        "\n",
        "    # Discriminator\n",
        "    D_prob = discriminator(Hat_New_X, H)\n",
        "\n",
        "    #%% Loss\n",
        "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
        "    return D_loss\n",
        "\n",
        "def generator_loss(X, M, New_X, H):\n",
        "    #%% Structure\n",
        "    # Generator\n",
        "    G_sample = generator(New_X,M)\n",
        "\n",
        "    # Combine with original data\n",
        "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
        "\n",
        "    # Discriminator\n",
        "    D_prob = discriminator(Hat_New_X, H)\n",
        "\n",
        "    #%% Loss\n",
        "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
        "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
        "\n",
        "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
        "\n",
        "    #%% MSE Performance metric\n",
        "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
        "    return G_loss, MSE_train_loss, MSE_test_loss\n",
        "    \n",
        "def test_loss(X, M, New_X):\n",
        "    #%% Structure\n",
        "    # Generator\n",
        "    G_sample = generator(New_X,M)\n",
        "\n",
        "    #%% MSE Performance metric\n",
        "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
        "    return MSE_test_loss, G_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5drKfXV39FtA"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooaDNx0t9FtB"
      },
      "source": [
        "optimizer_D = torch.optim.Adam(params=theta_D)\n",
        "optimizer_G = torch.optim.Adam(params=theta_G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo4T3Wuu9FtB"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "l2-SsyJe9FtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955,
          "referenced_widgets": [
            "24f0629818c8489d82a00e45669556d6",
            "fa0fcfc268d24bf0895367aa67f65efa",
            "0b166ec2feb04128b332db66a1990876",
            "968f367e54ab4a14a9ace2f9bccf2592",
            "ffd36c1d19df4571a9704be243e785c4",
            "8e1e38403ba54a4a8b9f094c2650ef79",
            "1f3ed440f7a046a7a098737e34cda9e0",
            "ba1bd7f75b194d84bfba214350edfc8d"
          ]
        },
        "outputId": "07378911-bb87-44e1-bd13-bcdad02b53cb"
      },
      "source": [
        "#%% Start Iterations\n",
        "for it in tqdm(range(5000)):    \n",
        "    \n",
        "    #%% Inputs\n",
        "    mb_idx = sample_idx(Train_No, mb_size)\n",
        "    X_mb = trainX[mb_idx,:]  \n",
        "    \n",
        "    Z_mb = sample_Z(mb_size, Dim) \n",
        "    M_mb = trainM[mb_idx,:]  \n",
        "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
        "    H_mb = M_mb * H_mb1\n",
        "    \n",
        "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
        "    \n",
        "\n",
        "    if use_gpu is True:\n",
        "        X_mb = torch.tensor(X_mb, device=\"cuda\")\n",
        "        M_mb = torch.tensor(M_mb, device=\"cuda\")\n",
        "        H_mb = torch.tensor(H_mb, device=\"cuda\")\n",
        "        New_X_mb = torch.tensor(New_X_mb, device=\"cuda\")\n",
        "    else:\n",
        "        X_mb = torch.tensor(X_mb, requires_grad=True)\n",
        "        X_mb = X_mb.float()\n",
        "        M_mb = torch.tensor(M_mb, requires_grad=True)\n",
        "        M_mb = M_mb.float()\n",
        "        H_mb = torch.tensor(H_mb, requires_grad=True)\n",
        "        H_mb = H_mb.float()\n",
        "        New_X_mb = torch.tensor(New_X_mb, requires_grad=True)\n",
        "        New_X_mb = New_X_mb.float()\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "    D_loss_curr = discriminator_loss(M=M_mb, New_X=New_X_mb, H=H_mb)\n",
        "    D_loss_curr.backward()\n",
        "    optimizer_D.step()\n",
        "    \n",
        "    optimizer_G.zero_grad()\n",
        "    G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = generator_loss(X=X_mb, M=M_mb, New_X=New_X_mb, H=H_mb)\n",
        "    G_loss_curr.backward()\n",
        "    optimizer_G.step()    \n",
        "        \n",
        "    #%% Intermediate Losses\n",
        "    if it % 100 == 0:\n",
        "        print('Iter: {}'.format(it),end='\\t')\n",
        "        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr.item())),end='\\t')\n",
        "        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr.item())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24f0629818c8489d82a00e45669556d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iter: 0\tTrain_loss: 0.5079\tTest_loss: 0.5079\n",
            "Iter: 100\tTrain_loss: 0.5067\tTest_loss: 0.5082\n",
            "Iter: 200\tTrain_loss: 0.5075\tTest_loss: 0.5062\n",
            "Iter: 300\tTrain_loss: 0.5072\tTest_loss: 0.5078\n",
            "Iter: 400\tTrain_loss: 0.5076\tTest_loss: 0.5077\n",
            "Iter: 500\tTrain_loss: 0.5072\tTest_loss: 0.5067\n",
            "Iter: 600\tTrain_loss: 0.5075\tTest_loss: 0.5065\n",
            "Iter: 700\tTrain_loss: 0.507\tTest_loss: 0.5063\n",
            "Iter: 800\tTrain_loss: 0.5065\tTest_loss: 0.506\n",
            "Iter: 900\tTrain_loss: 0.5075\tTest_loss: 0.5094\n",
            "Iter: 1000\tTrain_loss: 0.5066\tTest_loss: 0.5082\n",
            "Iter: 1100\tTrain_loss: 0.5053\tTest_loss: 0.5067\n",
            "Iter: 1200\tTrain_loss: 0.5077\tTest_loss: 0.5064\n",
            "Iter: 1300\tTrain_loss: 0.5072\tTest_loss: 0.5083\n",
            "Iter: 1400\tTrain_loss: 0.5052\tTest_loss: 0.5075\n",
            "Iter: 1500\tTrain_loss: 0.5061\tTest_loss: 0.5066\n",
            "Iter: 1600\tTrain_loss: 0.5061\tTest_loss: 0.5068\n",
            "Iter: 1700\tTrain_loss: 0.5076\tTest_loss: 0.5079\n",
            "Iter: 1800\tTrain_loss: 0.508\tTest_loss: 0.5102\n",
            "Iter: 1900\tTrain_loss: 0.5052\tTest_loss: 0.5058\n",
            "Iter: 2000\tTrain_loss: 0.5063\tTest_loss: 0.5062\n",
            "Iter: 2100\tTrain_loss: 0.5066\tTest_loss: 0.5083\n",
            "Iter: 2200\tTrain_loss: 0.5069\tTest_loss: 0.5076\n",
            "Iter: 2300\tTrain_loss: 0.507\tTest_loss: 0.5066\n",
            "Iter: 2400\tTrain_loss: 0.5069\tTest_loss: 0.5056\n",
            "Iter: 2500\tTrain_loss: 0.5072\tTest_loss: 0.5091\n",
            "Iter: 2600\tTrain_loss: 0.5071\tTest_loss: 0.5066\n",
            "Iter: 2700\tTrain_loss: 0.5064\tTest_loss: 0.5063\n",
            "Iter: 2800\tTrain_loss: 0.5078\tTest_loss: 0.5083\n",
            "Iter: 2900\tTrain_loss: 0.5069\tTest_loss: 0.5085\n",
            "Iter: 3000\tTrain_loss: 0.5069\tTest_loss: 0.507\n",
            "Iter: 3100\tTrain_loss: 0.5067\tTest_loss: 0.5054\n",
            "Iter: 3200\tTrain_loss: 0.5074\tTest_loss: 0.508\n",
            "Iter: 3300\tTrain_loss: 0.5068\tTest_loss: 0.5083\n",
            "Iter: 3400\tTrain_loss: 0.507\tTest_loss: 0.5061\n",
            "Iter: 3500\tTrain_loss: 0.5059\tTest_loss: 0.506\n",
            "Iter: 3600\tTrain_loss: 0.5071\tTest_loss: 0.5075\n",
            "Iter: 3700\tTrain_loss: 0.5067\tTest_loss: 0.5066\n",
            "Iter: 3800\tTrain_loss: 0.5074\tTest_loss: 0.5067\n",
            "Iter: 3900\tTrain_loss: 0.506\tTest_loss: 0.5058\n",
            "Iter: 4000\tTrain_loss: 0.506\tTest_loss: 0.5052\n",
            "Iter: 4100\tTrain_loss: 0.5076\tTest_loss: 0.507\n",
            "Iter: 4200\tTrain_loss: 0.5076\tTest_loss: 0.5074\n",
            "Iter: 4300\tTrain_loss: 0.5071\tTest_loss: 0.5092\n",
            "Iter: 4400\tTrain_loss: 0.5081\tTest_loss: 0.5079\n",
            "Iter: 4500\tTrain_loss: 0.5066\tTest_loss: 0.5061\n",
            "Iter: 4600\tTrain_loss: 0.5081\tTest_loss: 0.5075\n",
            "Iter: 4700\tTrain_loss: 0.5077\tTest_loss: 0.5073\n",
            "Iter: 4800\tTrain_loss: 0.5059\tTest_loss: 0.5069\n",
            "Iter: 4900\tTrain_loss: 0.5059\tTest_loss: 0.5058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTm9OHUZ9FtE"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-vEHQbN9FtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13501dd6-dc06-4e4c-bbbe-33446bdc6db1"
      },
      "source": [
        "Z_mb = sample_Z(Test_No, Dim) \n",
        "M_mb = testM\n",
        "X_mb = testX\n",
        "        \n",
        "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
        "\n",
        "if use_gpu is True:\n",
        "    X_mb = torch.tensor(X_mb, device='cuda')\n",
        "    M_mb = torch.tensor(M_mb, device='cuda')\n",
        "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
        "else:\n",
        "    X_mb = torch.tensor(X_mb)\n",
        "    X_mb = X_mb.float()\n",
        "    M_mb = torch.tensor(M_mb)\n",
        "    M_mb = M_mb.float()\n",
        "    New_X_mb = torch.tensor(New_X_mb)\n",
        "    New_X_mb = New_X_mb.float()\n",
        "    \n",
        "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
        "        \n",
        "print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Test RMSE: 0.5058268532921859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AOZ-Ins9FtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44527f46-99e3-4777-c92d-ade34c259789"
      },
      "source": [
        "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
        "print(\"Imputed test data:\")\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
        "\n",
        "if use_gpu is True:\n",
        "    print(imputed_data.cpu().detach().numpy())\n",
        "else:\n",
        "    print(imputed_data.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputed test data:\n",
            "[[0.00000000 0.03781512 0.00000000 ... 0.00019246 0.00040048 0.00246212]\n",
            " [0.00000000 0.03851540 0.10784312 ... 0.51717496 0.01391670 0.01256313]\n",
            " [0.00000000 0.00000000 0.00000000 ... 0.00000000 0.00000000 0.00018939]\n",
            " ...\n",
            " [0.00000000 0.00000000 0.00000000 ... 0.01677894 0.06938326 0.07127525]\n",
            " [0.01101321 0.53172213 0.53156918 ... 0.53961319 0.00951141 0.51062608]\n",
            " [0.00000000 0.99999994 0.00000000 ... 0.00072628 0.00040048 0.52682954]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAQ0apHD9FtG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}